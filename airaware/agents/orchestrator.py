"""
Agent Orchestrator for AirAware

This module provides coordination and orchestration of all intelligent agents.
"""

import asyncio
import logging
from dataclasses import dataclass, field
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
import json
from pathlib import Path

from .base_agent import BaseAgent, AgentConfig, AgentStatus
from .health_agent import HealthAdvisoryAgent, HealthAgentConfig
from .forecast_agent import ForecastOptimizationAgent, ForecastAgentConfig
from .data_agent import DataQualityAgent, DataAgentConfig
from .notification_agent import NotificationAgent, NotificationAgentConfig


@dataclass
class OrchestratorConfig(AgentConfig):
    """Configuration for Agent Orchestrator"""
    # Agent configurations
    health_agent_config: HealthAgentConfig = field(default_factory=HealthAgentConfig)
    forecast_agent_config: ForecastAgentConfig = field(default_factory=ForecastAgentConfig)
    data_agent_config: DataAgentConfig = field(default_factory=DataAgentConfig)
    notification_agent_config: NotificationAgentConfig = field(default_factory=NotificationAgentConfig)
    
    # Orchestration settings
    orchestration_interval: int = 300  # 5 minutes
    max_concurrent_agents: int = 4
    agent_timeout: int = 600  # 10 minutes
    
    # Coordination settings
    enable_agent_communication: bool = True
    enable_cross_agent_insights: bool = True
    enable_workflow_optimization: bool = True
    
    # Monitoring settings
    system_health_check_interval: int = 60  # 1 minute
    performance_monitoring_enabled: bool = True
    
    # Custom settings
    custom_settings: Dict[str, Any] = field(default_factory=lambda: {
        "workflow_cache_duration": 1800,  # 30 minutes
        "insight_generation_interval": 900,  # 15 minutes
        "max_workflow_history": 1000,
        "agent_restart_threshold": 3
    })


@dataclass
class WorkflowStep:
    """Workflow step definition"""
    step_id: str
    agent_id: str
    step_type: str  # "data_processing", "analysis", "notification", "optimization"
    dependencies: List[str] = field(default_factory=list)
    input_data: Dict[str, Any] = field(default_factory=dict)
    output_data: Dict[str, Any] = field(default_factory=dict)
    status: str = "pending"  # "pending", "running", "completed", "failed"
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    error_message: Optional[str] = None


@dataclass
class Workflow:
    """Workflow definition"""
    workflow_id: str
    workflow_type: str  # "forecast_generation", "health_assessment", "data_quality_check"
    steps: List[WorkflowStep]
    status: str = "pending"  # "pending", "running", "completed", "failed"
    created_at: datetime = field(default_factory=datetime.now)
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    total_duration: Optional[float] = None
    context: Dict[str, Any] = field(default_factory=dict)


@dataclass
class SystemInsight:
    """System insight generated by orchestrator"""
    insight_id: str
    insight_type: str  # "performance", "optimization", "anomaly", "recommendation"
    title: str
    description: str
    severity: str  # "low", "medium", "high", "critical"
    affected_agents: List[str]
    recommendations: List[str]
    timestamp: datetime = field(default_factory=datetime.now)
    resolved: bool = False


class AgentOrchestrator(BaseAgent):
    """Intelligent agent orchestrator and coordinator"""
    
    def __init__(self, config: OrchestratorConfig):
        super().__init__(config)
        
        # Initialize agents
        self.health_agent = HealthAdvisoryAgent(config.health_agent_config)
        self.forecast_agent = ForecastOptimizationAgent(config.forecast_agent_config)
        self.data_agent = DataQualityAgent(config.data_agent_config)
        self.notification_agent = NotificationAgent(config.notification_agent_config)
        
        # Agent registry
        self.agents: Dict[str, BaseAgent] = {
            "health": self.health_agent,
            "forecast": self.forecast_agent,
            "data": self.data_agent,
            "notification": self.notification_agent
        }
        
        # Workflow management
        self.active_workflows: Dict[str, Workflow] = {}
        self.workflow_history: List[Workflow] = []
        self.workflow_templates: Dict[str, List[WorkflowStep]] = {}
        
        # System insights
        self.system_insights: List[SystemInsight] = []
        self.agent_performance: Dict[str, Dict[str, Any]] = {}
        
        # Coordination state
        self.last_orchestration: Optional[datetime] = None
        self.system_health_status: str = "unknown"
        
        # Load workflow templates and system state
        self._load_workflow_templates()
        self._load_system_state()
    
    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """Execute orchestration logic"""
        try:
            # Extract context data
            workflow_type = context.get("workflow_type", "forecast_generation")
            station_id = context.get("station_id")
            user_id = context.get("user_id")
            pm25_data = context.get("pm25_data", {})
            forecast_data = context.get("forecast_data", [])
            
            # Create and execute workflow
            workflow = await self._create_workflow(workflow_type, context)
            result = await self._execute_workflow(workflow)
            
            # Generate system insights
            insights = await self._generate_system_insights()
            
            # Update system health
            health_status = await self._assess_system_health()
            
            # Coordinate agent communication
            if self.config.enable_agent_communication:
                await self._coordinate_agent_communication()
            
            # Optimize workflows
            if self.config.enable_workflow_optimization:
                await self._optimize_workflows()
            
            return {
                "status": "success",
                "timestamp": datetime.now().isoformat(),
                "workflow_result": result,
                "system_insights": [insight.__dict__ for insight in insights],
                "system_health": health_status,
                "active_workflows": len(self.active_workflows),
                "total_workflows": len(self.workflow_history)
            }
            
        except Exception as e:
            self.logger.error(f"Orchestration execution failed: {e}")
            raise
    
    async def health_check(self) -> bool:
        """Perform health check for the orchestrator and all agents"""
        try:
            # Check orchestrator health
            orchestrator_healthy = await super().health_check()
            
            # Check all agents
            agent_health = {}
            all_agents_healthy = True
            
            for agent_id, agent in self.agents.items():
                try:
                    agent_healthy = await agent.health_check()
                    agent_health[agent_id] = agent_healthy
                    if not agent_healthy:
                        all_agents_healthy = False
                except Exception as e:
                    self.logger.error(f"Health check failed for agent {agent_id}: {e}")
                    agent_health[agent_id] = False
                    all_agents_healthy = False
            
            # Update system health status
            if orchestrator_healthy and all_agents_healthy:
                self.system_health_status = "healthy"
            elif orchestrator_healthy and not all_agents_healthy:
                self.system_health_status = "degraded"
            else:
                self.system_health_status = "unhealthy"
            
            # Update health check timestamp
            self.last_health_check = datetime.now()
            
            return orchestrator_healthy and all_agents_healthy
            
        except Exception as e:
            self.logger.error(f"Orchestrator health check failed: {e}")
            return False
    
    async def _create_workflow(self, workflow_type: str, context: Dict[str, Any]) -> Workflow:
        """Create a new workflow based on type and context"""
        workflow_id = f"workflow_{workflow_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # Get workflow template
        template = self.workflow_templates.get(workflow_type, [])
        
        # Create workflow steps
        steps = []
        for step_template in template:
            step = WorkflowStep(
                step_id=f"{workflow_id}_{step_template['step_id']}",
                agent_id=step_template["agent_id"],
                step_type=step_template["step_type"],
                dependencies=step_template.get("dependencies", []),
                input_data=step_template.get("input_data", {})
            )
            steps.append(step)
        
        # Create workflow
        workflow = Workflow(
            workflow_id=workflow_id,
            workflow_type=workflow_type,
            steps=steps,
            context=context
        )
        
        # Store active workflow
        self.active_workflows[workflow_id] = workflow
        
        return workflow
    
    async def _execute_workflow(self, workflow: Workflow) -> Dict[str, Any]:
        """Execute a workflow"""
        workflow.status = "running"
        workflow.started_at = datetime.now()
        
        try:
            # Execute steps in dependency order
            completed_steps = []
            step_results = {}
            
            while len(completed_steps) < len(workflow.steps):
                # Find next executable steps
                executable_steps = []
                for step in workflow.steps:
                    if (step.status == "pending" and 
                        all(dep in completed_steps for dep in step.dependencies)):
                        executable_steps.append(step)
                
                if not executable_steps:
                    # No executable steps found, check for circular dependencies
                    pending_steps = [s for s in workflow.steps if s.status == "pending"]
                    if pending_steps:
                        raise Exception(f"Circular dependency detected in workflow {workflow.workflow_id}")
                    break
                
                # Execute steps concurrently
                tasks = []
                for step in executable_steps:
                    task = asyncio.create_task(self._execute_step(step, step_results))
                    tasks.append((step, task))
                
                # Wait for completion
                for step, task in tasks:
                    try:
                        result = await asyncio.wait_for(task, timeout=self.config.agent_timeout)
                        step.status = "completed"
                        step.end_time = datetime.now()
                        step.output_data = result
                        completed_steps.append(step.step_id)
                        step_results[step.step_id] = result
                        
                    except asyncio.TimeoutError:
                        step.status = "failed"
                        step.error_message = "Step execution timed out"
                        workflow.status = "failed"
                        break
                        
                    except Exception as e:
                        step.status = "failed"
                        step.error_message = str(e)
                        workflow.status = "failed"
                        break
            
            # Calculate workflow duration
            if workflow.status == "completed":
                workflow.completed_at = datetime.now()
                if workflow.started_at:
                    workflow.total_duration = (workflow.completed_at - workflow.started_at).total_seconds()
            
            # Move to history
            self.workflow_history.append(workflow)
            if workflow.workflow_id in self.active_workflows:
                del self.active_workflows[workflow.workflow_id]
            
            # Keep history size manageable
            if len(self.workflow_history) > self.config.custom_settings["max_workflow_history"]:
                self.workflow_history = self.workflow_history[-self.config.custom_settings["max_workflow_history"]:]
            
            return {
                "workflow_id": workflow.workflow_id,
                "status": workflow.status,
                "total_duration": workflow.total_duration,
                "completed_steps": len(completed_steps),
                "total_steps": len(workflow.steps),
                "step_results": step_results
            }
            
        except Exception as e:
            workflow.status = "failed"
            workflow.completed_at = datetime.now()
            if workflow.started_at:
                workflow.total_duration = (workflow.completed_at - workflow.started_at).total_seconds()
            
            self.logger.error(f"Workflow execution failed: {e}")
            raise
    
    async def _execute_step(self, step: WorkflowStep, step_results: Dict[str, Any]) -> Dict[str, Any]:
        """Execute a single workflow step"""
        step.status = "running"
        step.start_time = datetime.now()
        
        try:
            # Get agent
            agent = self.agents.get(step.agent_id)
            if not agent:
                raise Exception(f"Agent {step.agent_id} not found")
            
            # Prepare context
            context = step.input_data.copy()
            
            # Add results from dependent steps
            for dep in step.dependencies:
                if dep in step_results:
                    context.update(step_results[dep])
            
            # Execute agent
            result = await agent.run(context)
            
            # Update step
            step.status = "completed"
            step.end_time = datetime.now()
            step.output_data = result
            
            return result
            
        except Exception as e:
            step.status = "failed"
            step.error_message = str(e)
            step.end_time = datetime.now()
            raise
    
    async def _generate_system_insights(self) -> List[SystemInsight]:
        """Generate system insights from agent performance and workflows"""
        insights = []
        
        # Analyze agent performance
        for agent_id, agent in self.agents.items():
            metrics = agent.metrics
            
            # Check for performance issues
            if metrics.consecutive_failures >= 3:
                insight = SystemInsight(
                    insight_id=f"performance_{agent_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    insight_type="performance",
                    title=f"Performance Issue: {agent_id} Agent",
                    description=f"Agent {agent_id} has {metrics.consecutive_failures} consecutive failures",
                    severity="high",
                    affected_agents=[agent_id],
                    recommendations=[
                        f"Investigate {agent_id} agent failures",
                        "Check agent configuration and dependencies",
                        "Consider agent restart or reconfiguration"
                    ]
                )
                insights.append(insight)
            
            # Check for uptime issues
            if metrics.uptime_percentage < 80:
                insight = SystemInsight(
                    insight_id=f"uptime_{agent_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    insight_type="performance",
                    title=f"Uptime Issue: {agent_id} Agent",
                    description=f"Agent {agent_id} uptime is {metrics.uptime_percentage:.1f}%",
                    severity="medium",
                    affected_agents=[agent_id],
                    recommendations=[
                        f"Monitor {agent_id} agent stability",
                        "Check for resource constraints",
                        "Review agent error logs"
                    ]
                )
                insights.append(insight)
        
        # Analyze workflow performance
        recent_workflows = [
            w for w in self.workflow_history 
            if w.created_at >= datetime.now() - timedelta(hours=24)
        ]
        
        if recent_workflows:
            failed_workflows = [w for w in recent_workflows if w.status == "failed"]
            failure_rate = len(failed_workflows) / len(recent_workflows)
            
            if failure_rate > 0.1:  # 10% failure rate
                insight = SystemInsight(
                    insight_id=f"workflow_failure_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    insight_type="performance",
                    title="High Workflow Failure Rate",
                    description=f"Workflow failure rate is {failure_rate:.1%} in the last 24 hours",
                    severity="high",
                    affected_agents=list(self.agents.keys()),
                    recommendations=[
                        "Investigate workflow failure causes",
                        "Review agent dependencies and communication",
                        "Consider workflow optimization"
                    ]
                )
                insights.append(insight)
        
        # Store insights
        self.system_insights.extend(insights)
        
        # Keep insights manageable
        if len(self.system_insights) > 1000:
            self.system_insights = self.system_insights[-1000:]
        
        return insights
    
    async def _assess_system_health(self) -> Dict[str, Any]:
        """Assess overall system health"""
        health_status = {
            "overall_status": self.system_health_status,
            "timestamp": datetime.now().isoformat(),
            "agents": {},
            "workflows": {},
            "recommendations": []
        }
        
        # Assess agent health
        for agent_id, agent in self.agents.items():
            agent_health = {
                "status": agent.status.value,
                "uptime_percentage": agent.metrics.uptime_percentage,
                "consecutive_failures": agent.metrics.consecutive_failures,
                "last_execution": agent.metrics.last_execution_time.isoformat() if agent.metrics.last_execution_time else None
            }
            health_status["agents"][agent_id] = agent_health
        
        # Assess workflow health
        recent_workflows = [
            w for w in self.workflow_history 
            if w.created_at >= datetime.now() - timedelta(hours=24)
        ]
        
        if recent_workflows:
            completed_workflows = [w for w in recent_workflows if w.status == "completed"]
            failed_workflows = [w for w in recent_workflows if w.status == "failed"]
            
            health_status["workflows"] = {
                "total_workflows": len(recent_workflows),
                "completed_workflows": len(completed_workflows),
                "failed_workflows": len(failed_workflows),
                "success_rate": len(completed_workflows) / len(recent_workflows) if recent_workflows else 0,
                "average_duration": sum(w.total_duration for w in completed_workflows if w.total_duration) / len(completed_workflows) if completed_workflows else 0
            }
        
        # Generate recommendations
        if self.system_health_status == "unhealthy":
            health_status["recommendations"].append("System is unhealthy. Immediate attention required.")
        elif self.system_health_status == "degraded":
            health_status["recommendations"].append("System is degraded. Monitor closely and address issues.")
        
        return health_status
    
    async def _coordinate_agent_communication(self):
        """Coordinate communication between agents"""
        # This would implement inter-agent communication protocols
        # For now, it's a placeholder for future enhancement
        
        # Example: Share insights between agents
        if self.config.enable_cross_agent_insights:
            # Health agent could share health insights with notification agent
            # Data agent could share quality insights with forecast agent
            pass
    
    async def _optimize_workflows(self):
        """Optimize workflow execution"""
        # This would implement workflow optimization logic
        # For now, it's a placeholder for future enhancement
        
        # Example optimizations:
        # - Parallel execution of independent steps
        # - Caching of intermediate results
        # - Dynamic workflow adjustment based on performance
        pass
    
    def _load_workflow_templates(self):
        """Load workflow templates"""
        # Define default workflow templates
        self.workflow_templates = {
            "forecast_generation": [
                {
                    "step_id": "data_quality_check",
                    "agent_id": "data",
                    "step_type": "data_processing",
                    "dependencies": [],
                    "input_data": {"data_source": "forecast_input"}
                },
                {
                    "step_id": "forecast_optimization",
                    "agent_id": "forecast",
                    "step_type": "optimization",
                    "dependencies": ["data_quality_check"],
                    "input_data": {"optimization_type": "model_selection"}
                },
                {
                    "step_id": "health_assessment",
                    "agent_id": "health",
                    "step_type": "analysis",
                    "dependencies": ["forecast_optimization"],
                    "input_data": {"assessment_type": "forecast_health"}
                },
                {
                    "step_id": "notification_send",
                    "agent_id": "notification",
                    "step_type": "notification",
                    "dependencies": ["health_assessment"],
                    "input_data": {"notification_type": "forecast_alert"}
                }
            ],
            "health_assessment": [
                {
                    "step_id": "data_quality_check",
                    "agent_id": "data",
                    "step_type": "data_processing",
                    "dependencies": [],
                    "input_data": {"data_source": "health_input"}
                },
                {
                    "step_id": "health_analysis",
                    "agent_id": "health",
                    "step_type": "analysis",
                    "dependencies": ["data_quality_check"],
                    "input_data": {"analysis_type": "comprehensive"}
                },
                {
                    "step_id": "notification_send",
                    "agent_id": "notification",
                    "step_type": "notification",
                    "dependencies": ["health_analysis"],
                    "input_data": {"notification_type": "health_alert"}
                }
            ],
            "data_quality_check": [
                {
                    "step_id": "quality_assessment",
                    "agent_id": "data",
                    "step_type": "data_processing",
                    "dependencies": [],
                    "input_data": {"assessment_type": "comprehensive"}
                }
            ]
        }
    
    def _load_system_state(self):
        """Load system state from file"""
        try:
            state_path = Path("data/orchestrator_state.json")
            if state_path.exists():
                with open(state_path, 'r') as f:
                    data = json.load(f)
                
                # Load system insights
                self.system_insights = []
                for item in data.get("system_insights", []):
                    insight = SystemInsight(
                        insight_id=item["insight_id"],
                        insight_type=item["insight_type"],
                        title=item["title"],
                        description=item["description"],
                        severity=item["severity"],
                        affected_agents=item["affected_agents"],
                        recommendations=item["recommendations"],
                        timestamp=datetime.fromisoformat(item["timestamp"]),
                        resolved=item.get("resolved", False)
                    )
                    self.system_insights.append(insight)
                
                # Load agent performance
                self.agent_performance = data.get("agent_performance", {})
                
                self.logger.info("System state loaded successfully")
            else:
                self.logger.info("No system state file found, starting with empty state")
        except Exception as e:
            self.logger.error(f"Failed to load system state: {e}")
    
    def _save_system_state(self):
        """Save system state to file"""
        try:
            state_path = Path("data/orchestrator_state.json")
            state_path.parent.mkdir(parents=True, exist_ok=True)
            
            data = {
                "system_insights": [insight.__dict__ for insight in self.system_insights],
                "agent_performance": self.agent_performance,
                "last_save": datetime.now().isoformat()
            }
            
            with open(state_path, 'w') as f:
                json.dump(data, f, indent=2)
                
        except Exception as e:
            self.logger.error(f"Failed to save system state: {e}")
    
    def get_system_status(self) -> Dict[str, Any]:
        """Get comprehensive system status"""
        return {
            "orchestrator": self.get_status(),
            "agents": {agent_id: agent.get_status() for agent_id, agent in self.agents.items()},
            "workflows": {
                "active": len(self.active_workflows),
                "total_history": len(self.workflow_history),
                "recent_success_rate": self._calculate_recent_success_rate()
            },
            "insights": {
                "total": len(self.system_insights),
                "unresolved": len([i for i in self.system_insights if not i.resolved]),
                "critical": len([i for i in self.system_insights if i.severity == "critical" and not i.resolved])
            },
            "system_health": self.system_health_status,
            "last_orchestration": self.last_orchestration.isoformat() if self.last_orchestration else None
        }
    
    def _calculate_recent_success_rate(self) -> float:
        """Calculate recent workflow success rate"""
        recent_workflows = [
            w for w in self.workflow_history 
            if w.created_at >= datetime.now() - timedelta(hours=24)
        ]
        
        if not recent_workflows:
            return 0.0
        
        successful_workflows = [w for w in recent_workflows if w.status == "completed"]
        return len(successful_workflows) / len(recent_workflows)
    
    async def start_all_agents(self) -> Dict[str, bool]:
        """Start all agents"""
        results = {}
        for agent_id, agent in self.agents.items():
            try:
                result = await agent.start()
                results[agent_id] = result
            except Exception as e:
                self.logger.error(f"Failed to start agent {agent_id}: {e}")
                results[agent_id] = False
        return results
    
    async def stop_all_agents(self) -> Dict[str, bool]:
        """Stop all agents"""
        results = {}
        for agent_id, agent in self.agents.items():
            try:
                result = await agent.stop()
                results[agent_id] = result
            except Exception as e:
                self.logger.error(f"Failed to stop agent {agent_id}: {e}")
                results[agent_id] = False
        return results
